{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Genpact ML Hackathon: Meal Demand Forecasting System\n",
        "Features: XGBoost, NLP, FLAN-T5 for natural language interaction\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class MealDemandForecaster:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.label_encoders = {}\n",
        "        self.feature_cols = []\n",
        "        self.llm_tokenizer = None\n",
        "        self.llm_model = None\n",
        "\n",
        "    def load_data(self, train_path, center_path, meal_path):\n",
        "        \"\"\"Load all datasets\"\"\"\n",
        "        print(\"Loading datasets...\")\n",
        "        self.train_df = pd.read_csv(train_path)\n",
        "        self.center_df = pd.read_csv(center_path)\n",
        "        self.meal_df = pd.read_csv(meal_path)\n",
        "        print(f\"‚úì Train data: {self.train_df.shape}\")\n",
        "        print(f\"‚úì Center data: {self.center_df.shape}\")\n",
        "        print(f\"‚úì Meal data: {self.meal_df.shape}\")\n",
        "\n",
        "    def engineer_features(self, df, is_train=True):\n",
        "        \"\"\"Create advanced features including NLP-based features\"\"\"\n",
        "        if is_train:\n",
        "            print(\"\\nEngineering features...\")\n",
        "\n",
        "        # Merge with center and meal info\n",
        "        df = df.merge(self.center_df, on='center_id', how='left')\n",
        "        df = df.merge(self.meal_df, on='meal_id', how='left')\n",
        "\n",
        "        # Time-based features\n",
        "        df['week_mod_52'] = df['week'] % 52\n",
        "        df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52)\n",
        "        df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52)\n",
        "        df['is_holiday_season'] = ((df['week_mod_52'] >= 48) | (df['week_mod_52'] <= 2)).astype(int)\n",
        "        df['quarter'] = (df['week'] % 52) // 13 + 1\n",
        "\n",
        "        # Price features\n",
        "        df['discount_pct'] = ((df['base_price'] - df['checkout_price']) / df['base_price']) * 100\n",
        "        df['discount_pct'] = df['discount_pct'].clip(0, 100)\n",
        "        df['price_per_unit'] = df['checkout_price']\n",
        "        df['is_discounted'] = (df['discount_pct'] > 0).astype(int)\n",
        "\n",
        "        # Marketing features\n",
        "        df['total_promotion'] = df['emailer_for_promotion'] + df['homepage_featured']\n",
        "        df['promo_and_discount'] = df['emailer_for_promotion'] * df['is_discounted']\n",
        "\n",
        "        # Lag features and rolling statistics (only if num_orders exists)\n",
        "        if 'num_orders' in df.columns:\n",
        "            # Lag features (historical demand)\n",
        "            for lag in [1, 2, 3, 4, 8]:\n",
        "                df[f'lag_{lag}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(lag)\n",
        "\n",
        "            # Rolling statistics\n",
        "            for window in [3, 4, 8]:\n",
        "                df[f'rolling_mean_{window}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].transform(\n",
        "                    lambda x: x.rolling(window=window, min_periods=1).mean()\n",
        "                )\n",
        "                df[f'rolling_std_{window}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].transform(\n",
        "                    lambda x: x.rolling(window=window, min_periods=1).std()\n",
        "                )\n",
        "\n",
        "            # Exponential weighted moving average\n",
        "            df['ewm_demand'] = df.groupby(['center_id', 'meal_id'])['num_orders'].transform(\n",
        "                lambda x: x.ewm(span=4, adjust=False).mean()\n",
        "            )\n",
        "\n",
        "            # Center-based aggregations\n",
        "            df['center_avg_demand'] = df.groupby('center_id')['num_orders'].transform('mean')\n",
        "            df['center_std_demand'] = df.groupby('center_id')['num_orders'].transform('std')\n",
        "\n",
        "            # Meal-based aggregations\n",
        "            df['meal_avg_demand'] = df.groupby('meal_id')['num_orders'].transform('mean')\n",
        "            df['meal_std_demand'] = df.groupby('meal_id')['num_orders'].transform('std')\n",
        "\n",
        "            # Category-based aggregations\n",
        "            df['category_avg_demand'] = df.groupby('category')['num_orders'].transform('mean')\n",
        "            df['cuisine_avg_demand'] = df.groupby('cuisine')['num_orders'].transform('mean')\n",
        "\n",
        "            # Center type and region interactions\n",
        "            df['center_type_avg'] = df.groupby('center_type')['num_orders'].transform('mean')\n",
        "            df['region_avg'] = df.groupby('region_code')['num_orders'].transform('mean')\n",
        "\n",
        "            # Demand density (orders per operational area)\n",
        "            df['demand_density'] = df['num_orders'] / (df['op_area'] + 1)\n",
        "        else:\n",
        "            # For test data, use historical statistics from training data\n",
        "            # Create lag features with zeros (will be filled with historical data if available)\n",
        "            for lag in [1, 2, 3, 4, 8]:\n",
        "                df[f'lag_{lag}'] = 0\n",
        "\n",
        "            # Rolling statistics with zeros\n",
        "            for window in [3, 4, 8]:\n",
        "                df[f'rolling_mean_{window}'] = 0\n",
        "                df[f'rolling_std_{window}'] = 0\n",
        "\n",
        "            df['ewm_demand'] = 0\n",
        "\n",
        "            # Use stored aggregations from training\n",
        "            if hasattr(self, 'center_stats'):\n",
        "                df['center_avg_demand'] = df['center_id'].map(self.center_stats.get('avg', {}))\n",
        "                df['center_std_demand'] = df['center_id'].map(self.center_stats.get('std', {}))\n",
        "            else:\n",
        "                df['center_avg_demand'] = 0\n",
        "                df['center_std_demand'] = 0\n",
        "\n",
        "            if hasattr(self, 'meal_stats'):\n",
        "                df['meal_avg_demand'] = df['meal_id'].map(self.meal_stats.get('avg', {}))\n",
        "                df['meal_std_demand'] = df['meal_id'].map(self.meal_stats.get('std', {}))\n",
        "            else:\n",
        "                df['meal_avg_demand'] = 0\n",
        "                df['meal_std_demand'] = 0\n",
        "\n",
        "            if hasattr(self, 'category_stats'):\n",
        "                df['category_avg_demand'] = df['category'].map(self.category_stats)\n",
        "                df['cuisine_avg_demand'] = df['cuisine'].map(self.cuisine_stats)\n",
        "            else:\n",
        "                df['category_avg_demand'] = 0\n",
        "                df['cuisine_avg_demand'] = 0\n",
        "\n",
        "            if hasattr(self, 'center_type_stats'):\n",
        "                df['center_type_avg'] = df['center_type'].map(self.center_type_stats)\n",
        "                df['region_avg'] = df['region_code'].map(self.region_stats)\n",
        "            else:\n",
        "                df['center_type_avg'] = 0\n",
        "                df['region_avg'] = 0\n",
        "\n",
        "            df['demand_density'] = 0\n",
        "\n",
        "        # NLP-based features: Encode category and cuisine combinations\n",
        "        df['category_cuisine'] = df['category'] + '_' + df['cuisine']\n",
        "        df['center_meal_combo'] = df['center_id'].astype(str) + '_' + df['meal_id'].astype(str)\n",
        "\n",
        "        # Fill NaN values\n",
        "        df = df.fillna(0)\n",
        "\n",
        "        if is_train:\n",
        "            # Store statistics for test data\n",
        "            if 'num_orders' in df.columns:\n",
        "                self.center_stats = {\n",
        "                    'avg': df.groupby('center_id')['num_orders'].mean().to_dict(),\n",
        "                    'std': df.groupby('center_id')['num_orders'].std().to_dict()\n",
        "                }\n",
        "                self.meal_stats = {\n",
        "                    'avg': df.groupby('meal_id')['num_orders'].mean().to_dict(),\n",
        "                    'std': df.groupby('meal_id')['num_orders'].std().to_dict()\n",
        "                }\n",
        "                self.category_stats = df.groupby('category')['num_orders'].mean().to_dict()\n",
        "                self.cuisine_stats = df.groupby('cuisine')['num_orders'].mean().to_dict()\n",
        "                self.center_type_stats = df.groupby('center_type')['num_orders'].mean().to_dict()\n",
        "                self.region_stats = df.groupby('region_code')['num_orders'].mean().to_dict()\n",
        "\n",
        "            print(f\"‚úì Features engineered: {df.shape[1]} total columns\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def encode_categorical(self, df, fit=True):\n",
        "        \"\"\"Encode categorical variables\"\"\"\n",
        "        categorical_cols = ['center_id', 'meal_id', 'city_code', 'region_code',\n",
        "                           'center_type', 'category', 'cuisine', 'category_cuisine',\n",
        "                           'center_meal_combo']\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                if fit:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    # Store original values before encoding\n",
        "                    if col in ['category', 'cuisine']:\n",
        "                        if not hasattr(self, 'original_mappings'):\n",
        "                            self.original_mappings = {}\n",
        "                        self.original_mappings[col] = dict(zip(\n",
        "                            df[col].unique(),\n",
        "                            df[col].unique()\n",
        "                        ))\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col].astype(str))\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        # Handle unseen labels\n",
        "                        df[col] = df[col].astype(str).map(\n",
        "                            lambda x: self.label_encoders[col].transform([x])[0]\n",
        "                            if x in self.label_encoders[col].classes_ else -1\n",
        "                        )\n",
        "        return df\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        \"\"\"Prepare data for model training\"\"\"\n",
        "        print(\"\\nPreparing training data...\")\n",
        "\n",
        "        # Engineer features\n",
        "        self.train_df = self.engineer_features(self.train_df)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        self.train_df = self.encode_categorical(self.train_df, fit=True)\n",
        "\n",
        "        # Define feature columns\n",
        "        exclude_cols = ['id', 'num_orders']\n",
        "        self.feature_cols = [col for col in self.train_df.columns if col not in exclude_cols]\n",
        "\n",
        "        # Prepare X and y\n",
        "        X = self.train_df[self.feature_cols]\n",
        "        y = self.train_df['num_orders']\n",
        "\n",
        "        print(f\"‚úì Feature matrix: {X.shape}\")\n",
        "        print(f\"‚úì Target variable: {y.shape}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train_model(self, X, y):\n",
        "        \"\"\"Train XGBoost model\"\"\"\n",
        "        print(\"\\nTraining XGBoost model...\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # XGBoost parameters\n",
        "        params = {\n",
        "            'objective': 'reg:squaredlogerror',  # For RMSLE\n",
        "            'max_depth': 8,\n",
        "            'learning_rate': 0.05,\n",
        "            'n_estimators': 500,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'min_child_weight': 3,\n",
        "            'gamma': 0.1,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 1,\n",
        "            'random_state': 42,\n",
        "            'tree_method': 'hist',\n",
        "            'n_jobs': -1,\n",
        "            'early_stopping_rounds': 50  # Moved to params\n",
        "        }\n",
        "\n",
        "        # Train model\n",
        "        self.model = xgb.XGBRegressor(**params)\n",
        "        self.model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=100\n",
        "        )\n",
        "\n",
        "        # Calculate RMSLE on validation set\n",
        "        y_pred = self.model.predict(X_val)\n",
        "        y_pred = np.maximum(0, y_pred)  # Ensure non-negative predictions\n",
        "        rmsle = np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_val))**2))\n",
        "\n",
        "        print(f\"\\n‚úì Model trained successfully!\")\n",
        "        print(f\"‚úì Validation RMSLE: {rmsle:.4f}\")\n",
        "        print(f\"‚úì Competition Score: {100 * rmsle:.2f}\")\n",
        "\n",
        "        # Feature importance\n",
        "        self.feature_importance = pd.DataFrame({\n",
        "            'feature': self.feature_cols,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 Important Features:\")\n",
        "        print(self.feature_importance.head(10))\n",
        "\n",
        "    def load_llm(self):\n",
        "        \"\"\"Load FLAN-T5 for natural language interaction\"\"\"\n",
        "        print(\"\\nLoading FLAN-T5 model for natural language interaction...\")\n",
        "        try:\n",
        "            # Using FLAN-T5 small for faster inference\n",
        "            model_name = \"google/flan-t5-small\"\n",
        "            self.llm_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "            self.llm_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "            print(\"‚úì FLAN-T5 loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Could not load FLAN-T5: {e}\")\n",
        "            print(\"  Continuing without LLM features...\")\n",
        "\n",
        "    def predict_single(self, week, center_id, meal_id, checkout_price=None, base_price=None,\n",
        "                      emailer=0, homepage=0):\n",
        "        \"\"\"Make prediction for a single combination on-the-fly\"\"\"\n",
        "\n",
        "        # Create a single row dataframe\n",
        "        single_row = pd.DataFrame({\n",
        "            'week': [week],\n",
        "            'center_id': [center_id],\n",
        "            'meal_id': [meal_id],\n",
        "            'checkout_price': [checkout_price if checkout_price else 200],  # Default price\n",
        "            'base_price': [base_price if base_price else 250],\n",
        "            'emailer_for_promotion': [emailer],\n",
        "            'homepage_featured': [homepage]\n",
        "        })\n",
        "\n",
        "        # Add a temporary id\n",
        "        single_row['id'] = [999999]\n",
        "\n",
        "        # Engineer features\n",
        "        single_row = self.engineer_features(single_row, is_train=False)\n",
        "\n",
        "        # Encode categorical\n",
        "        single_row = self.encode_categorical(single_row, fit=False)\n",
        "\n",
        "        # Ensure all feature columns exist\n",
        "        for col in self.feature_cols:\n",
        "            if col not in single_row.columns:\n",
        "                single_row[col] = 0\n",
        "\n",
        "        # Prepare features\n",
        "        X_single = single_row[self.feature_cols]\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(X_single)[0]\n",
        "        prediction = max(0, prediction)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        \"\"\"Make predictions on test data\"\"\"\n",
        "        print(\"\\nMaking predictions on test data...\")\n",
        "\n",
        "        # Store original test data before transformations\n",
        "        original_test = test_df.copy()\n",
        "\n",
        "        # Engineer features (with is_train=False)\n",
        "        test_df = self.engineer_features(test_df, is_train=False)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        test_df = self.encode_categorical(test_df, fit=False)\n",
        "\n",
        "        # Ensure all feature columns exist\n",
        "        for col in self.feature_cols:\n",
        "            if col not in test_df.columns:\n",
        "                test_df[col] = 0\n",
        "\n",
        "        X_test = test_df[self.feature_cols]\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_test)\n",
        "        predictions = np.maximum(0, predictions)  # Ensure non-negative\n",
        "\n",
        "        # Add predictions to ORIGINAL test data (before encoding)\n",
        "        original_test['predicted_orders'] = predictions\n",
        "\n",
        "        print(f\"‚úì Predictions completed: {len(predictions)} records\")\n",
        "        print(f\"‚úì Average predicted demand: {predictions.mean():.2f}\")\n",
        "        print(f\"‚úì Min: {predictions.min():.2f}, Max: {predictions.max():.2f}\")\n",
        "\n",
        "        return original_test\n",
        "        \"\"\"Make predictions on test data\"\"\"\n",
        "        print(\"\\nMaking predictions...\")\n",
        "\n",
        "        # Engineer features\n",
        "        test_df = self.engineer_features(test_df)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        test_df = self.encode_categorical(test_df, fit=False)\n",
        "\n",
        "        # Ensure all feature columns exist\n",
        "        for col in self.feature_cols:\n",
        "            if col not in test_df.columns:\n",
        "                test_df[col] = 0\n",
        "\n",
        "        X_test = test_df[self.feature_cols]\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_test)\n",
        "        predictions = np.maximum(0, predictions)  # Ensure non-negative\n",
        "\n",
        "        test_df['predicted_orders'] = predictions\n",
        "\n",
        "        print(f\"‚úì Predictions completed: {len(predictions)} records\")\n",
        "        print(f\"‚úì Average predicted demand: {predictions.mean():.2f}\")\n",
        "        print(f\"‚úì Min: {predictions.min():.2f}, Max: {predictions.max():.2f}\")\n",
        "\n",
        "        return test_df\n",
        "\n",
        "    def explain_prediction_with_llm(self, center_id, meal_id, week, predicted_orders):\n",
        "        \"\"\"Use FLAN-T5 to generate natural language explanation\"\"\"\n",
        "\n",
        "        # Get meal and center info\n",
        "        meal_info = None\n",
        "        center_info = None\n",
        "\n",
        "        if hasattr(self, 'meal_df'):\n",
        "            meal_matches = self.meal_df[self.meal_df['meal_id'] == meal_id]\n",
        "            if len(meal_matches) > 0:\n",
        "                meal_info = meal_matches.iloc[0]\n",
        "\n",
        "        if hasattr(self, 'center_df'):\n",
        "            center_matches = self.center_df[self.center_df['center_id'] == center_id]\n",
        "            if len(center_matches) > 0:\n",
        "                center_info = center_matches.iloc[0]\n",
        "\n",
        "        # Create detailed context\n",
        "        category = meal_info['category'] if meal_info is not None else 'meal'\n",
        "        cuisine = meal_info['cuisine'] if meal_info is not None else 'various cuisine'\n",
        "        city = center_info['city_code'] if center_info is not None else 'the city'\n",
        "        center_type = center_info['center_type'] if center_info is not None else 'standard'\n",
        "\n",
        "        # Determine demand level\n",
        "        if predicted_orders < 100:\n",
        "            demand_level = \"low\"\n",
        "            recommendation = \"Consider reducing inventory and optimizing promotions\"\n",
        "        elif predicted_orders < 200:\n",
        "            demand_level = \"moderate\"\n",
        "            recommendation = \"Maintain standard stock levels\"\n",
        "        elif predicted_orders < 400:\n",
        "            demand_level = \"high\"\n",
        "            recommendation = \"Increase inventory and ensure adequate staffing\"\n",
        "        else:\n",
        "            demand_level = \"very high\"\n",
        "            recommendation = \"Maximize inventory, schedule extra staff, and prepare for peak demand\"\n",
        "\n",
        "        context = f\"\"\"Week {week} forecast for {category} ({cuisine}) at center {center_id} in city {city}:\n",
        "Expected orders: {int(predicted_orders)}\n",
        "Demand level: {demand_level}\n",
        "Center type: {center_type}\n",
        "Action: {recommendation}\"\"\"\n",
        "\n",
        "        if self.llm_model and self.llm_tokenizer:\n",
        "            try:\n",
        "                # Generate explanation using FLAN-T5\n",
        "                prompt = f\"Explain this restaurant delivery forecast clearly and professionally: {context}\"\n",
        "                inputs = self.llm_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs.input_ids,\n",
        "                    max_length=150,\n",
        "                    num_beams=4,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=False\n",
        "                )\n",
        "                explanation = self.llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "                # Add actionable insights\n",
        "                full_explanation = f\"{explanation}\\n\\n\"\n",
        "                full_explanation += f\"üì¶ Procurement Planning: {recommendation}\\n\"\n",
        "                full_explanation += f\"üéØ Demand Level: {demand_level.upper()} ({int(predicted_orders)} orders)\\n\"\n",
        "                full_explanation += f\"üìç Location: Center {center_id}, City {city}\\n\"\n",
        "                full_explanation += f\"üçΩÔ∏è Product: {category} - {cuisine}\"\n",
        "\n",
        "                return full_explanation\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö† LLM generation error: {e}\")\n",
        "                # Fall through to fallback\n",
        "\n",
        "        # Fallback explanation with rich details\n",
        "        explanation = f\"For week {week}, our model predicts {demand_level} demand with approximately {int(predicted_orders)} orders \"\n",
        "        explanation += f\"for {category} ({cuisine} cuisine) at fulfillment center {center_id} in city {city}.\\n\\n\"\n",
        "        explanation += f\"üì¶ Recommended Action: {recommendation}\\n\"\n",
        "        explanation += f\"üè¢ Center Type: {center_type}\\n\"\n",
        "        explanation += f\"üìä This forecast helps optimize inventory, staffing, and operational planning.\"\n",
        "\n",
        "        return explanation\n",
        "\n",
        "    def interactive_query(self, user_input):\n",
        "        \"\"\"Process natural language queries about forecasts\"\"\"\n",
        "        user_input_lower = user_input.lower()\n",
        "\n",
        "    def interactive_query(self, user_input):\n",
        "        \"\"\"Process natural language queries about forecasts\"\"\"\n",
        "        user_input_lower = user_input.lower()\n",
        "\n",
        "        # Parse intent - FORECAST\n",
        "        if 'forecast' in user_input_lower or 'predict' in user_input_lower:\n",
        "            import re\n",
        "            numbers = re.findall(r'\\d+', user_input)\n",
        "\n",
        "            if len(numbers) >= 3:\n",
        "                week, center, meal = int(numbers[0]), int(numbers[1]), int(numbers[2])\n",
        "\n",
        "                # First, try to look up in existing predictions\n",
        "                prediction_found = False\n",
        "                pred_value = 0\n",
        "                source = \"\"\n",
        "\n",
        "                if hasattr(self, 'predictions_df'):\n",
        "                    result = self.predictions_df[\n",
        "                        (self.predictions_df['week'] == week) &\n",
        "                        (self.predictions_df['center_id'] == center) &\n",
        "                        (self.predictions_df['meal_id'] == meal)\n",
        "                    ]\n",
        "\n",
        "                    if len(result) > 0:\n",
        "                        prediction_found = True\n",
        "                        pred_value = result.iloc[0]['predicted_orders']\n",
        "                        source = \"test data\"\n",
        "\n",
        "                # If not found, make on-the-fly prediction\n",
        "                if not prediction_found:\n",
        "                    try:\n",
        "                        pred_value = self.predict_single(week, center, meal)\n",
        "                        source = \"on-the-fly prediction\"\n",
        "                        prediction_found = True\n",
        "                    except Exception as e:\n",
        "                        return f\"‚ùå Could not make prediction: {e}\\n\\nTry with valid center and meal IDs.\"\n",
        "\n",
        "                # Build response\n",
        "                response = f\"üìä DEMAND FORECAST:\\n\\n\"\n",
        "                response += f\"  Week: {week}\\n\"\n",
        "                response += f\"  Center ID: {center}\\n\"\n",
        "                response += f\"  Meal ID: {meal}\\n\"\n",
        "\n",
        "                # Get meal info if available\n",
        "                meal_info = self.meal_df[self.meal_df['meal_id'] == meal]\n",
        "                if len(meal_info) > 0:\n",
        "                    response += f\"  Category: {meal_info.iloc[0]['category']}\\n\"\n",
        "                    response += f\"  Cuisine: {meal_info.iloc[0]['cuisine']}\\n\"\n",
        "\n",
        "                # Get center info if available\n",
        "                center_info = self.center_df[self.center_df['center_id'] == center]\n",
        "                if len(center_info) > 0:\n",
        "                    response += f\"  City: {center_info.iloc[0]['city_code']}\\n\"\n",
        "                    response += f\"  Region: {center_info.iloc[0]['region_code']}\\n\"\n",
        "\n",
        "                response += f\"\\n  üéØ PREDICTED ORDERS: {pred_value:.0f} orders/week\\n\"\n",
        "                response += f\"     (‚âà {pred_value/7:.0f} orders/day)\\n\"\n",
        "                response += f\"     Source: {source}\\n\\n\"\n",
        "\n",
        "                # Add recommendation based on demand level\n",
        "                if pred_value < 100:\n",
        "                    response += \"  üì¶ LOW Demand\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Recommendation: Minimal stock, basic staffing\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Risk: Low waste potential\\n\"\n",
        "                elif pred_value < 200:\n",
        "                    response += \"  üì¶ MODERATE Demand\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Recommendation: Standard inventory levels\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Risk: Medium - monitor closely\\n\"\n",
        "                elif pred_value < 400:\n",
        "                    response += \"  üì¶ HIGH Demand\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Recommendation: Increase inventory by 30-40%\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Risk: High - ensure adequate staffing\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Action: Schedule 2-3 extra staff members\\n\"\n",
        "                else:\n",
        "                    response += \"  üì¶ VERY HIGH Demand\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Recommendation: Maximum inventory preparation\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Risk: Critical - stock out potential\\n\"\n",
        "                    response += \"  ‚îî‚îÄ Action: All hands on deck, prepare 50% extra\\n\"\n",
        "\n",
        "                # Add cost/revenue estimates\n",
        "                avg_order_value = 250\n",
        "                response += f\"\\n  üí∞ Business Impact:\\n\"\n",
        "                response += f\"     ‚Ä¢ Expected Revenue: ‚Çπ{pred_value * avg_order_value:,.0f}/week\\n\"\n",
        "                response += f\"     ‚Ä¢ Raw Material Budget: ‚Çπ{pred_value * avg_order_value * 0.35:,.0f}/week\\n\"\n",
        "\n",
        "                return response\n",
        "\n",
        "            # If not enough numbers provided\n",
        "            response = \"ü§ñ I can forecast demand for any combination!\\n\\n\"\n",
        "            response += \"Please provide:\\n\"\n",
        "            response += \"  ‚Ä¢ Week number (1-155, or future weeks)\\n\"\n",
        "            response += \"  ‚Ä¢ Center ID (check your data for valid IDs)\\n\"\n",
        "            response += \"  ‚Ä¢ Meal ID (check your data for valid IDs)\\n\\n\"\n",
        "            response += \"Example: 'Forecast for week 150, center 10, meal 1885'\\n\\n\"\n",
        "            response += \"üí° Tip: Type 'sample' to see valid combinations from test data\"\n",
        "            return response\n",
        "\n",
        "        # Parse intent - TOP/BEST\n",
        "        if 'top' in user_input_lower or 'best' in user_input_lower or 'high' in user_input_lower:\n",
        "            try:\n",
        "                original_train = pd.read_csv('train.csv')\n",
        "                original_train = original_train.merge(self.center_df, on='center_id', how='left')\n",
        "                original_train = original_train.merge(self.meal_df, on='meal_id', how='left')\n",
        "\n",
        "                top_predictions = original_train.nlargest(10, 'num_orders')[\n",
        "                    ['week', 'center_id', 'meal_id', 'category', 'cuisine', 'num_orders']\n",
        "                ].drop_duplicates(subset=['center_id', 'meal_id']).head(5)\n",
        "\n",
        "                response = \"üèÜ Top 5 Historical High-Demand Combinations:\\n\\n\"\n",
        "                for idx, row in top_predictions.iterrows():\n",
        "                    response += f\"  {idx+1}. Center {int(row['center_id'])} - {row['category']} ({row['cuisine']})\\n\"\n",
        "                    response += f\"     ‚Üí {int(row['num_orders'])} orders/week (Week {int(row['week'])})\\n\\n\"\n",
        "                return response\n",
        "            except:\n",
        "                return \"Top performers data not available yet. Train the model first!\"\n",
        "\n",
        "        # Parse intent - FEATURES\n",
        "        if 'feature' in user_input_lower or 'important' in user_input_lower:\n",
        "            if hasattr(self, 'feature_importance'):\n",
        "                response = \"üîç Most Important Features for Prediction:\\n\\n\"\n",
        "                for idx, row in self.feature_importance.head(8).iterrows():\n",
        "                    feature = row['feature']\n",
        "                    if 'demand_density' in feature:\n",
        "                        explanation = \"(Orders per square km)\"\n",
        "                    elif 'ewm' in feature:\n",
        "                        explanation = \"(Recent trend)\"\n",
        "                    elif 'rolling_mean' in feature:\n",
        "                        explanation = \"(Moving average)\"\n",
        "                    elif 'lag' in feature:\n",
        "                        explanation = \"(Past week's orders)\"\n",
        "                    elif 'price' in feature or 'discount' in feature:\n",
        "                        explanation = \"(Pricing impact)\"\n",
        "                    elif 'promotion' in feature or 'emailer' in feature:\n",
        "                        explanation = \"(Marketing effect)\"\n",
        "                    else:\n",
        "                        explanation = \"\"\n",
        "\n",
        "                    response += f\"  {idx+1}. {row['feature']}: {row['importance']:.4f} {explanation}\\n\"\n",
        "                response += \"\\nüí° These features have the biggest impact on demand forecasts!\"\n",
        "                return response\n",
        "            return \"Feature importance not available. Train the model first!\"\n",
        "\n",
        "        # Parse intent - SUMMARY\n",
        "        if 'summary' in user_input_lower or 'overview' in user_input_lower:\n",
        "            response = \"üìà FORECAST SUMMARY:\\n\\n\"\n",
        "\n",
        "            try:\n",
        "                original_train = pd.read_csv('train.csv')\n",
        "                original_train = original_train.merge(self.center_df, on='center_id', how='left')\n",
        "                original_train = original_train.merge(self.meal_df, on='meal_id', how='left')\n",
        "\n",
        "                response += f\"  üìä Dataset Statistics:\\n\"\n",
        "                response += f\"     ‚Ä¢ Total historical records: {len(original_train):,}\\n\"\n",
        "                response += f\"     ‚Ä¢ Average weekly demand: {original_train['num_orders'].mean():.2f} orders\\n\"\n",
        "                response += f\"     ‚Ä¢ Peak demand: {original_train['num_orders'].max():.0f} orders\\n\"\n",
        "                response += f\"     ‚Ä¢ Unique centers: {original_train['center_id'].nunique()}\\n\"\n",
        "                response += f\"     ‚Ä¢ Unique meals: {original_train['meal_id'].nunique()}\\n\"\n",
        "                response += f\"     ‚Ä¢ Date range: Week {original_train['week'].min()} to {original_train['week'].max()}\\n\\n\"\n",
        "\n",
        "                if hasattr(self, 'predictions_df'):\n",
        "                    response += f\"  üéØ Predictions Generated:\\n\"\n",
        "                    response += f\"     ‚Ä¢ Total predictions: {len(self.predictions_df):,}\\n\"\n",
        "                    response += f\"     ‚Ä¢ Forecast weeks: {self.predictions_df['week'].min()} to {self.predictions_df['week'].max()}\\n\"\n",
        "                    response += f\"     ‚Ä¢ Avg predicted demand: {self.predictions_df['predicted_orders'].mean():.2f} orders/week\\n\"\n",
        "                    response += f\"     ‚Ä¢ Peak predicted: {self.predictions_df['predicted_orders'].max():.0f} orders\\n\"\n",
        "                return response\n",
        "            except:\n",
        "                return \"Could not load summary data.\"\n",
        "\n",
        "        # Parse intent - CATEGORY/CUISINE\n",
        "        if 'category' in user_input_lower or 'cuisine' in user_input_lower:\n",
        "            try:\n",
        "                original_train = pd.read_csv('train.csv')\n",
        "                original_train = original_train.merge(self.meal_df, on='meal_id', how='left')\n",
        "\n",
        "                response = \"üçΩÔ∏è MEAL CATEGORIES & CUISINES:\\n\\n\"\n",
        "\n",
        "                cat_stats = original_train.groupby('category')['num_orders'].agg(['mean', 'sum']).sort_values('sum', ascending=False)\n",
        "                response += \"  Top Categories by Total Demand:\\n\"\n",
        "                for cat, row in cat_stats.head(5).iterrows():\n",
        "                    response += f\"    ‚Ä¢ {cat}: {row['sum']:,.0f} total orders (avg: {row['mean']:.1f}/week)\\n\"\n",
        "\n",
        "                response += \"\\n  Top Cuisines by Total Demand:\\n\"\n",
        "                cui_stats = original_train.groupby('cuisine')['num_orders'].agg(['mean', 'sum']).sort_values('sum', ascending=False)\n",
        "                for cui, row in cui_stats.head(5).iterrows():\n",
        "                    response += f\"    ‚Ä¢ {cui}: {row['sum']:,.0f} total orders (avg: {row['mean']:.1f}/week)\\n\"\n",
        "                return response\n",
        "            except:\n",
        "                return \"Could not load category/cuisine data.\"\n",
        "\n",
        "        # Parse intent - SAMPLE\n",
        "        if 'sample' in user_input_lower or 'show prediction' in user_input_lower:\n",
        "            if hasattr(self, 'predictions_df') and len(self.predictions_df) > 0:\n",
        "                response = \"üìã SAMPLE PREDICTIONS:\\n\\n\"\n",
        "                samples = self.predictions_df.head(10)\n",
        "                for idx, row in samples.iterrows():\n",
        "                    response += f\"  ‚Ä¢ Week {int(row['week'])}, Center {int(row['center_id'])}, Meal {int(row['meal_id'])}\\n\"\n",
        "                    response += f\"    ‚Üí {row['predicted_orders']:.0f} orders/week\\n\"\n",
        "                return response\n",
        "            return \"No predictions available. Run model with test data first.\"\n",
        "\n",
        "        # Parse intent - HELP\n",
        "        if 'help' in user_input_lower or '?' in user_input_lower:\n",
        "            response = \"ü§ñ AVAILABLE COMMANDS:\\n\\n\"\n",
        "            response += \"  üìä 'forecast for week X, center Y, meal Z' - Get specific prediction\\n\"\n",
        "            response += \"  üìã 'show predictions' or 'sample' - See sample forecasts\\n\"\n",
        "            response += \"  üèÜ 'top' or 'best' - See high-performing meals\\n\"\n",
        "            response += \"  üîç 'features' or 'important' - View key prediction factors\\n\"\n",
        "            response += \"  üìà 'summary' or 'overview' - Get data overview\\n\"\n",
        "            response += \"  üçΩÔ∏è 'category' or 'cuisine' - Analyze meal types\\n\"\n",
        "            response += \"  üí° 'example' - Get AI-generated explanation\\n\"\n",
        "            response += \"  ‚ùå 'quit' or 'exit' - End session\\n\"\n",
        "            return response\n",
        "\n",
        "        # Default response\n",
        "        response = \"I can help you with:\\n\\n\"\n",
        "        response += \"  1. üìä Specific demand forecasts (provide week, center, meal IDs)\\n\"\n",
        "        response += \"  2. üìã Sample predictions from the test data\\n\"\n",
        "        response += \"  3. üèÜ Top performing meal-center combinations\\n\"\n",
        "        response += \"  4. üîç Important features affecting demand\\n\"\n",
        "        response += \"  5. üìà Data summaries and overviews\\n\"\n",
        "        response += \"  6. üçΩÔ∏è Category and cuisine analysis\\n\"\n",
        "        response += \"\\nType 'help' for detailed commands or ask any question!\"\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"MEAL DEMAND FORECASTING SYSTEM\")\n",
        "    print(\"XGBoost + NLP + FLAN-T5 Integration\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize forecaster\n",
        "    forecaster = MealDemandForecaster()\n",
        "\n",
        "    # Check if files exist\n",
        "    import os\n",
        "    required_files = ['train.csv', 'fulfilment_center_info.csv', 'meal_info.csv']\n",
        "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "    if missing_files:\n",
        "        print(\"\\n‚ö† Missing required files:\")\n",
        "        for f in missing_files:\n",
        "            print(f\"  - {f}\")\n",
        "        print(\"\\nPlease ensure all CSV files are in the current directory.\")\n",
        "        print(\"You can still explore the code structure and methodology.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Load data\n",
        "        forecaster.load_data(\n",
        "            'train.csv',\n",
        "            'fulfilment_center_info.csv',\n",
        "            'meal_info.csv'\n",
        "        )\n",
        "\n",
        "        # Prepare and train\n",
        "        X, y = forecaster.prepare_training_data()\n",
        "        forecaster.train_model(X, y)\n",
        "\n",
        "        # Load LLM\n",
        "        forecaster.load_llm()\n",
        "\n",
        "        # Make predictions on test set if available\n",
        "        if os.path.exists('test.csv'):\n",
        "            test_df = pd.read_csv('test.csv')\n",
        "            predictions = forecaster.predict(test_df)\n",
        "\n",
        "            # Store predictions for interactive queries\n",
        "            forecaster.predictions_df = predictions\n",
        "\n",
        "            # Debug: Verify predictions are stored\n",
        "            print(f\"\\n‚úì Predictions stored: {len(forecaster.predictions_df)} rows\")\n",
        "            print(f\"‚úì Columns available: {list(forecaster.predictions_df.columns)}\")\n",
        "            print(f\"‚úì Sample data:\")\n",
        "            print(forecaster.predictions_df[['week', 'center_id', 'meal_id', 'predicted_orders']].head(3))\n",
        "\n",
        "            # Save predictions\n",
        "            submission = predictions[['id', 'predicted_orders']]\n",
        "            submission.columns = ['id', 'num_orders']\n",
        "            submission.to_csv('submission.csv', index=False)\n",
        "            print(\"\\n‚úì Submission file created: submission.csv\")\n",
        "\n",
        "            # Show sample predictions with actual details\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"SAMPLE PREDICTIONS (First 10):\")\n",
        "            print(\"=\" * 70)\n",
        "            sample_display = predictions[['week', 'center_id', 'meal_id', 'predicted_orders']].head(10)\n",
        "            for idx, row in sample_display.iterrows():\n",
        "                print(f\"Week {int(row['week'])}, Center {int(row['center_id'])}, Meal {int(row['meal_id'])}: {row['predicted_orders']:.0f} orders/week\")\n",
        "        else:\n",
        "            print(\"\\n‚ö† test.csv not found. Skipping predictions.\")\n",
        "            predictions = None\n",
        "\n",
        "\n",
        "        # Interactive mode\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"INTERACTIVE MODE - Ask questions in natural language!\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"\\nExamples:\")\n",
        "        print(\"  - 'Show me the top performing meals'\")\n",
        "        print(\"  - 'What features are most important?'\")\n",
        "        print(\"  - 'Give me an example explanation'\")\n",
        "        print(\"  - 'What's the forecast summary?'\")\n",
        "\n",
        "        while True:\n",
        "            user_query = input(\"\\nü§ñ Your question (or 'quit' to exit): \")\n",
        "            if user_query.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"\\nüëã Thanks for using the Meal Demand Forecasting System!\")\n",
        "                break\n",
        "\n",
        "            response = forecaster.interactive_query(user_query)\n",
        "            print(f\"\\nüí° {response}\")\n",
        "\n",
        "            # Generate AI explanation for examples\n",
        "            if 'example' in user_query.lower() and predictions is not None:\n",
        "                print(\"\\n\" + \"-\" * 70)\n",
        "                print(\"AI-GENERATED EXPLANATION (Using FLAN-T5):\")\n",
        "                print(\"-\" * 70)\n",
        "                sample_pred = predictions.iloc[0]\n",
        "                explanation = forecaster.explain_prediction_with_llm(\n",
        "                    sample_pred['center_id'],\n",
        "                    sample_pred['meal_id'],\n",
        "                    sample_pred['week'],\n",
        "                    sample_pred['predicted_orders']\n",
        "                )\n",
        "                print(f\"üéØ {explanation}\")\n",
        "                print(\"-\" * 70)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"Session complete!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdCREPnrFFaj",
        "outputId": "052fb3ce-5ca1-4463-d184-faad46f0ec52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MEAL DEMAND FORECASTING SYSTEM\n",
            "XGBoost + NLP + FLAN-T5 Integration\n",
            "======================================================================\n",
            "Loading datasets...\n",
            "‚úì Train data: (456548, 9)\n",
            "‚úì Center data: (77, 5)\n",
            "‚úì Meal data: (51, 3)\n",
            "\n",
            "Preparing training data...\n",
            "\n",
            "Engineering features...\n",
            "‚úì Features engineered: 48 total columns\n",
            "‚úì Feature matrix: (456548, 46)\n",
            "‚úì Target variable: (456548,)\n",
            "\n",
            "Training XGBoost model...\n",
            "[0]\tvalidation_0-rmsle:4.41022\n",
            "[100]\tvalidation_0-rmsle:1.24956\n",
            "[200]\tvalidation_0-rmsle:0.38708\n",
            "[300]\tvalidation_0-rmsle:0.36111\n",
            "[400]\tvalidation_0-rmsle:0.35095\n",
            "[499]\tvalidation_0-rmsle:0.34365\n",
            "\n",
            "‚úì Model trained successfully!\n",
            "‚úì Validation RMSLE: 0.3437\n",
            "‚úì Competition Score: 34.37\n",
            "\n",
            "Top 10 Important Features:\n",
            "                  feature  importance\n",
            "43         demand_density    0.453249\n",
            "28         rolling_mean_3    0.220625\n",
            "34             ewm_demand    0.201116\n",
            "19         price_per_unit    0.022953\n",
            "25                  lag_3    0.012193\n",
            "3          checkout_price    0.011637\n",
            "5   emailer_for_promotion    0.008602\n",
            "31          rolling_std_4    0.008230\n",
            "27                  lag_8    0.006900\n",
            "26                  lag_4    0.006869\n",
            "\n",
            "Loading FLAN-T5 model for natural language interaction...\n",
            "‚úì FLAN-T5 loaded successfully!\n",
            "\n",
            "Making predictions on test data...\n",
            "‚úì Predictions completed: 32573 records\n",
            "‚úì Average predicted demand: 12.14\n",
            "‚úì Min: 8.15, Max: 16.81\n",
            "\n",
            "‚úì Predictions stored: 32573 rows\n",
            "‚úì Columns available: ['id', 'week', 'center_id', 'meal_id', 'checkout_price', 'base_price', 'emailer_for_promotion', 'homepage_featured', 'predicted_orders']\n",
            "‚úì Sample data:\n",
            "   week  center_id  meal_id  predicted_orders\n",
            "0   146         55     1885         11.724892\n",
            "1   146         55     1993         11.724892\n",
            "2   146         55     2539          9.033693\n",
            "\n",
            "‚úì Submission file created: submission.csv\n",
            "\n",
            "======================================================================\n",
            "SAMPLE PREDICTIONS (First 10):\n",
            "======================================================================\n",
            "Week 146, Center 55, Meal 1885: 12 orders/week\n",
            "Week 146, Center 55, Meal 1993: 12 orders/week\n",
            "Week 146, Center 55, Meal 2539: 9 orders/week\n",
            "Week 146, Center 55, Meal 2631: 11 orders/week\n",
            "Week 146, Center 55, Meal 1248: 11 orders/week\n",
            "Week 146, Center 55, Meal 1778: 10 orders/week\n",
            "Week 146, Center 55, Meal 1062: 10 orders/week\n",
            "Week 146, Center 55, Meal 2707: 12 orders/week\n",
            "Week 146, Center 55, Meal 1207: 11 orders/week\n",
            "Week 146, Center 55, Meal 1230: 11 orders/week\n",
            "\n",
            "======================================================================\n",
            "INTERACTIVE MODE - Ask questions in natural language!\n",
            "======================================================================\n",
            "\n",
            "Examples:\n",
            "  - 'Show me the top performing meals'\n",
            "  - 'What features are most important?'\n",
            "  - 'Give me an example explanation'\n",
            "  - 'What's the forecast summary?'\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): forecast for week 200, center 99, meal 5000\n",
            "\n",
            "üí° üìä DEMAND FORECAST:\n",
            "\n",
            "  Week: 200\n",
            "  Center ID: 99\n",
            "  Meal ID: 5000\n",
            "  City: 596\n",
            "  Region: 71\n",
            "\n",
            "  üéØ PREDICTED ORDERS: 12 orders/week\n",
            "     (‚âà 2 orders/day)\n",
            "     Source: on-the-fly prediction\n",
            "\n",
            "  üì¶ LOW Demand\n",
            "  ‚îî‚îÄ Recommendation: Minimal stock, basic staffing\n",
            "  ‚îî‚îÄ Risk: Low waste potential\n",
            "\n",
            "  üí∞ Business Impact:\n",
            "     ‚Ä¢ Expected Revenue: ‚Çπ2,914/week\n",
            "     ‚Ä¢ Raw Material Budget: ‚Çπ1,020/week\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): forecast for week 146, center 55, meal 1885\n",
            "\n",
            "üí° üìä DEMAND FORECAST:\n",
            "\n",
            "  Week: 146\n",
            "  Center ID: 55\n",
            "  Meal ID: 1885\n",
            "  Category: Beverages\n",
            "  Cuisine: Thai\n",
            "  City: 647\n",
            "  Region: 56\n",
            "\n",
            "  üéØ PREDICTED ORDERS: 12 orders/week\n",
            "     (‚âà 2 orders/day)\n",
            "     Source: test data\n",
            "\n",
            "  üì¶ LOW Demand\n",
            "  ‚îî‚îÄ Recommendation: Minimal stock, basic staffing\n",
            "  ‚îî‚îÄ Risk: Low waste potential\n",
            "\n",
            "  üí∞ Business Impact:\n",
            "     ‚Ä¢ Expected Revenue: ‚Çπ2,931/week\n",
            "     ‚Ä¢ Raw Material Budget: ‚Çπ1,026/week\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): top orders right now\n",
            "\n",
            "üí° üèÜ Top 5 Historical High-Demand Combinations:\n",
            "\n",
            "  14051. Center 43 - Rice Bowl (Indian)\n",
            "     ‚Üí 24299 orders/week (Week 5)\n",
            "\n",
            "  13924. Center 10 - Rice Bowl (Indian)\n",
            "     ‚Üí 13580 orders/week (Week 5)\n",
            "\n",
            "  413352. Center 43 - Sandwich (Italian)\n",
            "     ‚Üí 13150 orders/week (Week 132)\n",
            "\n",
            "  12069. Center 89 - Rice Bowl (Indian)\n",
            "     ‚Üí 12489 orders/week (Week 5)\n",
            "\n",
            "  90858. Center 146 - Sandwich (Italian)\n",
            "     ‚Üí 12327 orders/week (Week 32)\n",
            "\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): centers with most orders \n",
            "\n",
            "üí° I can help you with:\n",
            "\n",
            "  1. üìä Specific demand forecasts (provide week, center, meal IDs)\n",
            "  2. üìã Sample predictions from the test data\n",
            "  3. üèÜ Top performing meal-center combinations\n",
            "  4. üîç Important features affecting demand\n",
            "  5. üìà Data summaries and overviews\n",
            "  6. üçΩÔ∏è Category and cuisine analysis\n",
            "\n",
            "Type 'help' for detailed commands or ask any question!\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): top performing meal-center\n",
            "\n",
            "üí° üèÜ Top 5 Historical High-Demand Combinations:\n",
            "\n",
            "  14051. Center 43 - Rice Bowl (Indian)\n",
            "     ‚Üí 24299 orders/week (Week 5)\n",
            "\n",
            "  13924. Center 10 - Rice Bowl (Indian)\n",
            "     ‚Üí 13580 orders/week (Week 5)\n",
            "\n",
            "  413352. Center 43 - Sandwich (Italian)\n",
            "     ‚Üí 13150 orders/week (Week 132)\n",
            "\n",
            "  12069. Center 89 - Rice Bowl (Indian)\n",
            "     ‚Üí 12489 orders/week (Week 5)\n",
            "\n",
            "  90858. Center 146 - Sandwich (Italian)\n",
            "     ‚Üí 12327 orders/week (Week 32)\n",
            "\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): top performing meal-center\n",
            "\n",
            "üí° üèÜ Top 5 Historical High-Demand Combinations:\n",
            "\n",
            "  14051. Center 43 - Rice Bowl (Indian)\n",
            "     ‚Üí 24299 orders/week (Week 5)\n",
            "\n",
            "  13924. Center 10 - Rice Bowl (Indian)\n",
            "     ‚Üí 13580 orders/week (Week 5)\n",
            "\n",
            "  413352. Center 43 - Sandwich (Italian)\n",
            "     ‚Üí 13150 orders/week (Week 132)\n",
            "\n",
            "  12069. Center 89 - Rice Bowl (Indian)\n",
            "     ‚Üí 12489 orders/week (Week 5)\n",
            "\n",
            "  90858. Center 146 - Sandwich (Italian)\n",
            "     ‚Üí 12327 orders/week (Week 32)\n",
            "\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): forecast for week 146, center 55, meal 1885\n",
            "\n",
            "üí° üìä DEMAND FORECAST:\n",
            "\n",
            "  Week: 146\n",
            "  Center ID: 55\n",
            "  Meal ID: 1885\n",
            "  Category: Beverages\n",
            "  Cuisine: Thai\n",
            "  City: 647\n",
            "  Region: 56\n",
            "\n",
            "  üéØ PREDICTED ORDERS: 12 orders/week\n",
            "     (‚âà 2 orders/day)\n",
            "     Source: test data\n",
            "\n",
            "  üì¶ LOW Demand\n",
            "  ‚îî‚îÄ Recommendation: Minimal stock, basic staffing\n",
            "  ‚îî‚îÄ Risk: Low waste potential\n",
            "\n",
            "  üí∞ Business Impact:\n",
            "     ‚Ä¢ Expected Revenue: ‚Çπ2,931/week\n",
            "     ‚Ä¢ Raw Material Budget: ‚Çπ1,026/week\n",
            "\n",
            "\n",
            "ü§ñ Your question (or 'quit' to exit): quit\n",
            "\n",
            "üëã Thanks for using the Meal Demand Forecasting System!\n",
            "\n",
            "======================================================================\n",
            "Session complete!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}